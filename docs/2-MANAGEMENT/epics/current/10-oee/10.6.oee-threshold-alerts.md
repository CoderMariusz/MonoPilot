# 10.6 - OEE Threshold Alerts

**Priority**: P0 (MVP)
**Story Points**: M (Medium)
**Type**: backend
**Phase**: 1B (Alerts & Reports)
**Model**: OPUS

**State:** ready
**Estimate:** M (3-4 days)
**Primary PRD:** `docs/1-BASELINE/product/modules/oee.md` (FR-OEE-010)
**Architecture:** Database schema, alert engine

---

## Goal

Implement real-time threshold-based alerting system for OEE metrics. Enable automatic monitoring of performance indicators (OEE, availability, downtime duration) and trigger alerts when thresholds are breached. Provide in-app notifications and email alerts to ensure proactive response to production issues.

---

## User Story

As a **Production Manager**, I want to **receive automatic alerts when OEE metrics fall below thresholds or downtime exceeds limits** so that **I can respond quickly to production issues before they significantly impact output**.

As a **Supervisor**, I want to **configure alert rules for my production line and acknowledge alerts when I take action** so that **I can track response times and ensure nothing is missed**.

---

## Scope

**In scope (this story)**
- `performance_alerts` table with alert tracking
- Alert rule configuration (thresholds, severities, notification channels)
- Alert triggering logic (OEE < 85% warning, < 75% critical, downtime > 30min)
- In-app notification system
- Email notification integration
- Alert acknowledgment workflow
- GET /api/oee/alerts - List alerts with filters
- GET /api/oee/alerts/active - Active alerts only
- POST /api/oee/alerts/config - Create alert rule
- PATCH /api/oee/alerts/:id/acknowledge - Acknowledge alert
- PATCH /api/oee/alerts/:id/resolve - Resolve alert
- Alert dashboard widget
- Alert notification badge

**Out of scope (this story)**
- SMS notifications (Phase 2)
- Push notifications to mobile app (Phase 3)
- Alert escalation rules (Phase 2)
- Alert analytics/reporting (Phase 2)
- Integration with external notification systems (Slack, Teams) (Phase 3)

---

## Dependencies

### Cross-Epic Dependencies

| Dependency | Story/Epic | Type | What It Provides | Status |
|------------|------------|------|------------------|--------|
| 01.1 | Org Context + RLS | HARD | organizations, users tables | Ready |
| 04.2 | Machine Operations | HARD | Operation start/stop, timing data | Ready |

### Within Epic Dependencies

| Dependency | Story | Type | What It Provides |
|------------|-------|------|------------------|
| 10.1 | OEE Settings & Targets | HARD | performance_targets for threshold configuration |
| 10.3 | Downtime Event Tracking | HARD | oee_downtime_events for downtime alerts |
| 10.4 | OEE Calculation Engine | HARD | oee_snapshots for OEE metric alerts |

### Provides To (Downstream)

| Story | What This Provides |
|-------|-------------------|
| 10.7 | Shift Report Generation - alert summary in reports |
| 10.14 | Email Alerts & Shift Handover - email notification infrastructure |
| 10.18 | Performance Dashboard - alert count widgets |

---

## Database Migration

### Migration: Create performance_alerts table

```sql
-- Migration: YYYYMMDDHHMMSS_create_performance_alerts.sql

CREATE TABLE performance_alerts (
    -- Identity
    id                      UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    org_id                  UUID NOT NULL REFERENCES organizations(id),

    -- Alert Type and Classification
    alert_type              TEXT NOT NULL
                            CHECK (alert_type IN (
                                'oee_below_target',
                                'availability_low',
                                'performance_low',
                                'quality_low',
                                'downtime_extended',
                                'energy_spike',
                                'shift_oee_miss'
                            )),
    severity                TEXT NOT NULL
                            CHECK (severity IN ('low', 'medium', 'high', 'critical')),

    -- Metric Details
    metric_name             TEXT NOT NULL,
    threshold_value         NUMERIC(10, 2) NOT NULL,
    actual_value            NUMERIC(10, 2) NOT NULL,
    unit                    TEXT,

    -- Reference (what triggered the alert)
    reference_type          TEXT NOT NULL
                            CHECK (reference_type IN (
                                'machine',
                                'line',
                                'work_order',
                                'shift',
                                'organization'
                            )),
    reference_id            UUID NOT NULL,
    reference_name          TEXT,

    -- Alert Context
    snapshot_id             UUID REFERENCES oee_snapshots(id),
    downtime_event_id       UUID REFERENCES oee_downtime_events(id),
    shift_id                UUID REFERENCES shifts(id),
    machine_id              UUID REFERENCES machines(id),
    line_id                 UUID REFERENCES production_lines(id),
    work_order_id           UUID REFERENCES work_orders(id),

    -- Alert Lifecycle
    status                  TEXT NOT NULL DEFAULT 'active'
                            CHECK (status IN ('active', 'acknowledged', 'resolved', 'dismissed')),
    triggered_at            TIMESTAMPTZ NOT NULL DEFAULT now(),
    acknowledged_by         UUID REFERENCES users(id),
    acknowledged_at         TIMESTAMPTZ,
    resolved_by             UUID REFERENCES users(id),
    resolved_at             TIMESTAMPTZ,
    resolution_notes        TEXT,

    -- Notification Status
    notification_sent       BOOLEAN DEFAULT false,
    notification_method     TEXT,
    notification_sent_at    TIMESTAMPTZ,
    notification_error      TEXT,

    -- Additional Context
    message                 TEXT,
    details                 JSONB,

    -- Audit
    created_at              TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at              TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- =============================================================================
-- Indexes for Performance
-- =============================================================================

CREATE INDEX idx_alerts_org_status ON performance_alerts(org_id, status);
CREATE INDEX idx_alerts_active ON performance_alerts(org_id, status, triggered_at)
    WHERE status IN ('active', 'acknowledged');
CREATE INDEX idx_alerts_type ON performance_alerts(org_id, alert_type);
CREATE INDEX idx_alerts_severity ON performance_alerts(org_id, severity);
CREATE INDEX idx_alerts_machine ON performance_alerts(machine_id) WHERE machine_id IS NOT NULL;
CREATE INDEX idx_alerts_line ON performance_alerts(line_id) WHERE line_id IS NOT NULL;
CREATE INDEX idx_alerts_wo ON performance_alerts(work_order_id) WHERE work_order_id IS NOT NULL;
CREATE INDEX idx_alerts_triggered ON performance_alerts(org_id, triggered_at);
CREATE INDEX idx_alerts_reference ON performance_alerts(org_id, reference_type, reference_id);

-- =============================================================================
-- Alert Rules Configuration
-- =============================================================================

CREATE TABLE alert_rules (
    id                      UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    org_id                  UUID NOT NULL REFERENCES organizations(id),

    -- Rule Identification
    name                    TEXT NOT NULL,
    description             TEXT,
    alert_type              TEXT NOT NULL,

    -- Scope
    scope_type              TEXT NOT NULL DEFAULT 'organization'
                            CHECK (scope_type IN ('organization', 'line', 'machine')),
    scope_id                UUID,

    -- Threshold Configuration
    metric_name             TEXT NOT NULL,
    threshold_operator      TEXT NOT NULL
                            CHECK (threshold_operator IN ('lt', 'lte', 'gt', 'gte', 'eq', 'neq')),
    threshold_value         NUMERIC(10, 2) NOT NULL,
    unit                    TEXT,

    -- Time Window
    evaluation_period_min   INTEGER,
    consecutive_violations  INTEGER DEFAULT 1,

    -- Severity
    severity                TEXT NOT NULL
                            CHECK (severity IN ('low', 'medium', 'high', 'critical')),

    -- Notification Configuration
    notify_email            BOOLEAN DEFAULT false,
    notify_in_app           BOOLEAN DEFAULT true,
    notify_sms              BOOLEAN DEFAULT false,
    email_recipients        TEXT[],
    sms_recipients          TEXT[],

    -- Status
    is_active               BOOLEAN DEFAULT true,

    -- Audit
    created_at              TIMESTAMPTZ NOT NULL DEFAULT now(),
    created_by              UUID REFERENCES users(id),
    updated_at              TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_by              UUID REFERENCES users(id),

    CONSTRAINT uq_alert_rule_name UNIQUE (org_id, name)
);

CREATE INDEX idx_alert_rules_org ON alert_rules(org_id);
CREATE INDEX idx_alert_rules_active ON alert_rules(org_id, is_active) WHERE is_active = true;
CREATE INDEX idx_alert_rules_scope ON alert_rules(org_id, scope_type, scope_id);

-- =============================================================================
-- RLS Policies
-- =============================================================================

ALTER TABLE performance_alerts ENABLE ROW LEVEL SECURITY;

CREATE POLICY "alerts_select" ON performance_alerts
    FOR SELECT USING (
        org_id = (SELECT org_id FROM users WHERE id = auth.uid())
    );

CREATE POLICY "alerts_insert" ON performance_alerts
    FOR INSERT WITH CHECK (
        org_id = (SELECT org_id FROM users WHERE id = auth.uid())
    );

CREATE POLICY "alerts_update" ON performance_alerts
    FOR UPDATE USING (
        org_id = (SELECT org_id FROM users WHERE id = auth.uid())
    );

ALTER TABLE alert_rules ENABLE ROW LEVEL SECURITY;

CREATE POLICY "alert_rules_select" ON alert_rules
    FOR SELECT USING (
        org_id = (SELECT org_id FROM users WHERE id = auth.uid())
    );

CREATE POLICY "alert_rules_insert" ON alert_rules
    FOR INSERT WITH CHECK (
        org_id = (SELECT org_id FROM users WHERE id = auth.uid())
    );

CREATE POLICY "alert_rules_update" ON alert_rules
    FOR UPDATE USING (
        org_id = (SELECT org_id FROM users WHERE id = auth.uid())
    );

-- =============================================================================
-- Trigger for updated_at
-- =============================================================================

CREATE TRIGGER update_performance_alerts_updated_at
    BEFORE UPDATE ON performance_alerts
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_alert_rules_updated_at
    BEFORE UPDATE ON alert_rules
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- =============================================================================
-- Function: Evaluate OEE Alert Thresholds
-- =============================================================================

CREATE OR REPLACE FUNCTION evaluate_oee_alert_thresholds()
RETURNS TRIGGER AS $$
DECLARE
    v_rule RECORD;
    v_alert_exists BOOLEAN;
BEGIN
    -- Only evaluate on new snapshots or updates
    IF NEW.oee_pct IS NULL THEN
        RETURN NEW;
    END IF;

    -- Find applicable alert rules
    FOR v_rule IN
        SELECT *
        FROM alert_rules
        WHERE org_id = NEW.org_id
          AND is_active = true
          AND alert_type IN ('oee_below_target', 'availability_low', 'performance_low', 'quality_low')
          AND (
              scope_type = 'organization' OR
              (scope_type = 'machine' AND scope_id = NEW.machine_id) OR
              (scope_type = 'line' AND scope_id = NEW.line_id)
          )
    LOOP
        -- Check if threshold violated
        IF (
            (v_rule.threshold_operator = 'lt' AND
             CASE v_rule.metric_name
                 WHEN 'oee' THEN NEW.oee_pct
                 WHEN 'availability' THEN NEW.availability_pct
                 WHEN 'performance' THEN NEW.performance_pct
                 WHEN 'quality' THEN NEW.quality_pct
             END < v_rule.threshold_value)
            OR
            (v_rule.threshold_operator = 'lte' AND
             CASE v_rule.metric_name
                 WHEN 'oee' THEN NEW.oee_pct
                 WHEN 'availability' THEN NEW.availability_pct
                 WHEN 'performance' THEN NEW.performance_pct
                 WHEN 'quality' THEN NEW.quality_pct
             END <= v_rule.threshold_value)
        ) THEN
            -- Check if alert already exists
            SELECT EXISTS(
                SELECT 1 FROM performance_alerts
                WHERE org_id = NEW.org_id
                  AND status IN ('active', 'acknowledged')
                  AND alert_type = v_rule.alert_type
                  AND reference_type = CASE
                      WHEN v_rule.scope_type = 'machine' THEN 'machine'
                      WHEN v_rule.scope_type = 'line' THEN 'line'
                      ELSE 'organization'
                  END
                  AND reference_id = COALESCE(
                      CASE WHEN v_rule.scope_type = 'machine' THEN NEW.machine_id END,
                      CASE WHEN v_rule.scope_type = 'line' THEN NEW.line_id END,
                      NEW.org_id
                  )
                  AND triggered_at > NOW() - INTERVAL '1 hour'
            ) INTO v_alert_exists;

            -- Create alert if doesn't exist
            IF NOT v_alert_exists THEN
                INSERT INTO performance_alerts (
                    org_id,
                    alert_type,
                    severity,
                    metric_name,
                    threshold_value,
                    actual_value,
                    unit,
                    reference_type,
                    reference_id,
                    snapshot_id,
                    machine_id,
                    line_id,
                    work_order_id,
                    shift_id,
                    message,
                    details
                ) VALUES (
                    NEW.org_id,
                    v_rule.alert_type,
                    v_rule.severity,
                    v_rule.metric_name,
                    v_rule.threshold_value,
                    CASE v_rule.metric_name
                        WHEN 'oee' THEN NEW.oee_pct
                        WHEN 'availability' THEN NEW.availability_pct
                        WHEN 'performance' THEN NEW.performance_pct
                        WHEN 'quality' THEN NEW.quality_pct
                    END,
                    '%',
                    CASE
                        WHEN v_rule.scope_type = 'machine' THEN 'machine'
                        WHEN v_rule.scope_type = 'line' THEN 'line'
                        ELSE 'organization'
                    END,
                    COALESCE(
                        CASE WHEN v_rule.scope_type = 'machine' THEN NEW.machine_id END,
                        CASE WHEN v_rule.scope_type = 'line' THEN NEW.line_id END,
                        NEW.org_id
                    ),
                    NEW.id,
                    NEW.machine_id,
                    NEW.line_id,
                    NEW.work_order_id,
                    NEW.shift_id,
                    format('%s is %s%% (threshold: %s%%)',
                        UPPER(v_rule.metric_name),
                        CASE v_rule.metric_name
                            WHEN 'oee' THEN NEW.oee_pct
                            WHEN 'availability' THEN NEW.availability_pct
                            WHEN 'performance' THEN NEW.performance_pct
                            WHEN 'quality' THEN NEW.quality_pct
                        END,
                        v_rule.threshold_value
                    ),
                    jsonb_build_object(
                        'rule_id', v_rule.id,
                        'rule_name', v_rule.name,
                        'snapshot_time', NEW.snapshot_time
                    )
                );
            END IF;
        END IF;
    END LOOP;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_evaluate_oee_alerts
    AFTER INSERT OR UPDATE ON oee_snapshots
    FOR EACH ROW
    EXECUTE FUNCTION evaluate_oee_alert_thresholds();

-- =============================================================================
-- Function: Evaluate Downtime Alert Thresholds
-- =============================================================================

CREATE OR REPLACE FUNCTION evaluate_downtime_alert_thresholds()
RETURNS TRIGGER AS $$
DECLARE
    v_rule RECORD;
    v_duration_min INTEGER;
BEGIN
    -- Only evaluate when downtime ends
    IF NEW.end_time IS NULL OR OLD.end_time IS NOT NULL THEN
        RETURN NEW;
    END IF;

    v_duration_min := NEW.duration_minutes;

    -- Find applicable alert rules for extended downtime
    FOR v_rule IN
        SELECT *
        FROM alert_rules
        WHERE org_id = NEW.org_id
          AND is_active = true
          AND alert_type = 'downtime_extended'
          AND (
              scope_type = 'organization' OR
              (scope_type = 'machine' AND scope_id = NEW.machine_id) OR
              (scope_type = 'line' AND scope_id = NEW.line_id)
          )
    LOOP
        -- Check if duration exceeds threshold
        IF (
            (v_rule.threshold_operator = 'gt' AND v_duration_min > v_rule.threshold_value) OR
            (v_rule.threshold_operator = 'gte' AND v_duration_min >= v_rule.threshold_value)
        ) THEN
            -- Create alert
            INSERT INTO performance_alerts (
                org_id,
                alert_type,
                severity,
                metric_name,
                threshold_value,
                actual_value,
                unit,
                reference_type,
                reference_id,
                downtime_event_id,
                machine_id,
                line_id,
                work_order_id,
                message,
                details
            ) VALUES (
                NEW.org_id,
                'downtime_extended',
                v_rule.severity,
                'downtime_duration',
                v_rule.threshold_value,
                v_duration_min,
                'minutes',
                CASE
                    WHEN v_rule.scope_type = 'machine' THEN 'machine'
                    WHEN v_rule.scope_type = 'line' THEN 'line'
                    ELSE 'organization'
                END,
                COALESCE(
                    CASE WHEN v_rule.scope_type = 'machine' THEN NEW.machine_id END,
                    CASE WHEN v_rule.scope_type = 'line' THEN NEW.line_id END,
                    NEW.org_id
                ),
                NEW.id,
                NEW.machine_id,
                NEW.line_id,
                NEW.work_order_id,
                format('Downtime exceeded %s minutes (actual: %s min)',
                    v_rule.threshold_value,
                    v_duration_min
                ),
                jsonb_build_object(
                    'rule_id', v_rule.id,
                    'rule_name', v_rule.name,
                    'downtime_type', NEW.downtime_type,
                    'reason_code_id', NEW.reason_code_id,
                    'start_time', NEW.start_time,
                    'end_time', NEW.end_time
                )
            );
        END IF;
    END LOOP;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_evaluate_downtime_alerts
    AFTER INSERT OR UPDATE ON oee_downtime_events
    FOR EACH ROW
    EXECUTE FUNCTION evaluate_downtime_alert_thresholds();
```

---

## Acceptance Criteria (Given/When/Then)

### AC-1: Alert Rules Configuration

```gherkin
Scenario: Create OEE threshold alert rule
  Given user navigates to OEE Settings > Alerts
  When user clicks [+ New Alert Rule]
  And enters:
    | Field | Value |
    | Name | Low OEE Warning |
    | Alert Type | oee_below_target |
    | Metric | OEE |
    | Threshold | < 85% |
    | Severity | Medium |
    | Scope | Organization |
    | Notify Email | true |
  And clicks [Create]
  Then alert rule created
  And rule is active
  And success toast "Alert rule created"

Scenario: Machine-specific alert rule
  Given user creating alert rule
  When selecting scope = Machine
  And selecting machine = Mixer-01
  And threshold = OEE < 80%
  Then rule applies only to Mixer-01
  And alerts triggered only for that machine
```

### AC-2: OEE Threshold Alert Triggering

```gherkin
Scenario: OEE falls below warning threshold
  Given alert rule: OEE < 85% (severity: medium)
  And machine currently at OEE 88%
  When new OEE snapshot calculated with 82%
  Then performance_alert created with:
    | Field | Value |
    | alert_type | oee_below_target |
    | severity | medium |
    | threshold_value | 85 |
    | actual_value | 82 |
    | status | active |
  And in-app notification shown
  And email sent if configured

Scenario: OEE falls below critical threshold
  Given alert rule: OEE < 75% (severity: critical)
  When OEE snapshot shows 72%
  Then alert created with severity = critical
  And notification marked as high priority
  And alert appears at top of dashboard

Scenario: Duplicate alert prevention
  Given active alert for Machine-01 OEE < 85%
  And alert triggered 10 minutes ago
  When another snapshot shows OEE 83%
  Then no new alert created
  And existing alert remains active
```

### AC-3: Downtime Duration Alert

```gherkin
Scenario: Downtime exceeds threshold
  Given alert rule: Downtime > 30 minutes (severity: high)
  And downtime event started at 14:00
  When downtime ends at 14:35 (35 minutes)
  Then alert created with:
    | Field | Value |
    | alert_type | downtime_extended |
    | threshold_value | 30 |
    | actual_value | 35 |
    | severity | high |
  And downtime_event_id linked

Scenario: Planned downtime no alert
  Given alert rule applies to unplanned downtime only
  When planned downtime (lunch) = 30 minutes
  Then no alert triggered
```

### AC-4: Alert Acknowledgment

```gherkin
Scenario: Acknowledge alert
  Given active alert with id = alert-123
  And user is Production Manager
  When user clicks [Acknowledge] on alert
  And optionally adds note "Investigating issue"
  Then alert.status = 'acknowledged'
  And alert.acknowledged_by = current user
  And alert.acknowledged_at = now
  And alert badge count decrements
  And other users see "Acknowledged by John Smith"

Scenario: Cannot acknowledge already acknowledged alert
  Given alert already acknowledged by User A
  When User B tries to acknowledge
  Then warning "Already acknowledged by User A at 14:23"
  And option to add note instead
```

### AC-5: Alert Resolution

```gherkin
Scenario: Resolve alert
  Given acknowledged alert
  When user clicks [Resolve]
  And enters resolution note "OEE back to 87%, issue cleared"
  Then alert.status = 'resolved'
  And alert.resolved_by = current user
  And alert.resolved_at = now
  And alert removed from active list
  And appears in resolved history

Scenario: Auto-resolve when condition clears
  Given active alert: OEE < 85% (actual 82%)
  When new snapshot shows OEE = 88%
  Then alert auto-resolved
  And resolution_notes = "Threshold condition cleared"
```

### AC-6: In-App Notifications

```gherkin
Scenario: Alert notification displayed
  Given alert triggered
  When user on dashboard or any page
  Then notification badge appears on alerts icon
  And count shows number of active alerts
  And notification panel shows latest alerts
  And clicking notification navigates to alert detail

Scenario: Notification panel
  Given 5 active alerts
  When user clicks notifications icon
  Then panel shows alerts sorted by severity then time
  And critical alerts shown first (red)
  And each alert shows:
    | Field | Display |
    | Icon | Color-coded by severity |
    | Message | "OEE below 85% (82%)" |
    | Reference | "Machine: Mixer-01" |
    | Time | "5 minutes ago" |
  And [Acknowledge] and [View] buttons available
```

### AC-7: Email Notifications

```gherkin
Scenario: Email sent for critical alert
  Given alert rule with notify_email = true
  And email_recipients = ['manager@example.com']
  And alert severity = critical
  When alert triggered
  Then email sent within 1 minute
  And email contains:
    | Field | Content |
    | Subject | "[CRITICAL] OEE Alert: Mixer-01" |
    | Body | Alert details, metric values, link to dashboard |
  And notification_sent = true
  And notification_sent_at = timestamp

Scenario: Email failure handling
  Given email configured
  When email delivery fails
  Then notification_error logged
  And retry attempted (3 max)
  And admin notified of delivery failure
```

### AC-8: Alert Dashboard Widget

```gherkin
Scenario: Active alerts widget on dashboard
  Given user on /oee/dashboard
  When page loads
  Then "Active Alerts" widget displays:
    | Count | Severity | Actions |
    | 2 | Critical | [View All] |
    | 3 | Medium | |
  And clicking count navigates to /oee/alerts
  And clicking alert card navigates to detail

Scenario: No active alerts
  Given no active alerts
  Then widget shows "No active alerts"
  And green checkmark icon
  And message "All systems operating normally"
```

### AC-9: Alert List Page

```gherkin
Scenario: View all alerts
  Given user navigates to /oee/alerts
  When page loads
  Then DataTable displays alerts with columns:
    | Column | Content |
    | Severity | Badge (critical/high/medium/low) |
    | Type | Alert type name |
    | Message | Alert message |
    | Reference | Machine/Line name |
    | Value | Actual vs Threshold |
    | Triggered | Time ago |
    | Status | Badge |
    | Actions | Acknowledge, Resolve, View |
  And filters available: Status, Severity, Type, Date Range

Scenario: Filter by status
  Given alerts with various statuses
  When user filters by status = 'active'
  Then only active alerts displayed
  And acknowledged/resolved hidden
```

### AC-10: Alert Detail View

```gherkin
Scenario: View alert details
  Given alert exists
  When user clicks alert to view detail
  Then page shows:
    | Section | Content |
    | Header | Alert type, severity badge, status |
    | Metric | Threshold vs Actual with visual |
    | Reference | Link to machine/line/WO |
    | Timeline | Triggered, acknowledged, resolved times |
    | Context | Snapshot/downtime event details |
    | Actions | Acknowledge, Resolve buttons |
    | History | Acknowledgment, resolution notes |

Scenario: Navigate to related entities
  Given alert references Machine-01
  When user clicks machine link
  Then navigate to /oee/machines/machine-01
  And machine detail page loads
```

### AC-11: Multiple Alert Types

```gherkin
Scenario: Availability alert
  Given alert rule: Availability < 80%
  When availability drops to 75%
  Then alert triggered with type = 'availability_low'

Scenario: Performance alert
  Given alert rule: Performance < 85% for 30 minutes
  When performance at 82% for consecutive 30 min
  Then alert triggered with type = 'performance_low'

Scenario: Quality alert
  Given alert rule: Quality < 95%
  When quality drops to 92%
  Then alert triggered with type = 'quality_low'
```

### AC-12: Alert Rule Management

```gherkin
Scenario: Edit alert rule
  Given existing alert rule
  When user edits threshold from 85% to 80%
  And clicks [Save]
  Then rule updated
  And future alerts use new threshold
  And existing active alerts unaffected

Scenario: Deactivate alert rule
  Given active alert rule
  When user toggles is_active = false
  Then rule stops triggering new alerts
  And existing alerts remain
  And rule can be reactivated

Scenario: Delete alert rule
  Given alert rule with no active alerts
  When user clicks [Delete]
  And confirms deletion
  Then rule deleted
  And cannot trigger new alerts
```

### AC-13: Permission Enforcement

```gherkin
Scenario: Manager can configure alerts
  Given user with PRODUCTION_MANAGER role
  Then can create, edit, delete alert rules
  And can acknowledge and resolve alerts

Scenario: Supervisor can acknowledge
  Given user with SUPERVISOR role
  Then can acknowledge and resolve alerts
  And cannot create/edit alert rules

Scenario: Operator view only
  Given user with OPERATOR role
  Then can view alerts
  And cannot acknowledge or configure
```

### AC-14: Performance Requirements

```gherkin
Scenario: Alert triggering performance
  Given OEE snapshot calculated
  When alert evaluation runs
  Then alert created within 5 seconds
  And notification sent within 10 seconds

Scenario: Alert list performance
  Given 1000 alerts in database
  When loading /oee/alerts with pagination
  Then response time < 500ms
  And active alerts load first
```

### AC-15: RLS Policy Enforcement

```gherkin
Scenario: Org isolation on alerts
  Given User A from Org A and User B from Org B
  When User A requests GET /api/oee/alerts
  Then only Org A alerts returned

Scenario: Cannot acknowledge alert from different org
  Given alert belongs to Org B
  When User A (Org A) tries to acknowledge
  Then 404 Not Found returned
```

---

## Implementation Notes

### API Endpoints

```typescript
// GET /api/oee/alerts
interface AlertListParams {
  status?: 'active' | 'acknowledged' | 'resolved' | 'dismissed';
  severity?: 'low' | 'medium' | 'high' | 'critical';
  alert_type?: string;
  reference_type?: string;
  reference_id?: string;
  date_from?: string;
  date_to?: string;
  page?: number;
  limit?: number;
}

interface AlertListResponse {
  alerts: PerformanceAlert[];
  pagination: { total: number; page: number; limit: number; pages: number };
}

interface PerformanceAlert {
  id: string;
  org_id: string;
  alert_type: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  metric_name: string;
  threshold_value: number;
  actual_value: number;
  unit: string;
  reference_type: string;
  reference_id: string;
  reference_name: string;
  status: 'active' | 'acknowledged' | 'resolved' | 'dismissed';
  triggered_at: string;
  acknowledged_by?: string;
  acknowledged_at?: string;
  resolved_by?: string;
  resolved_at?: string;
  message: string;
  details: any;
  notification_sent: boolean;
  created_at: string;
}

// GET /api/oee/alerts/active
interface ActiveAlertsResponse {
  alerts: PerformanceAlert[];
  counts: {
    critical: number;
    high: number;
    medium: number;
    low: number;
    total: number;
  };
}

// POST /api/oee/alerts/config
interface CreateAlertRuleRequest {
  name: string;
  description?: string;
  alert_type: string;
  scope_type: 'organization' | 'line' | 'machine';
  scope_id?: string;
  metric_name: string;
  threshold_operator: 'lt' | 'lte' | 'gt' | 'gte';
  threshold_value: number;
  unit?: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  notify_email?: boolean;
  notify_in_app?: boolean;
  email_recipients?: string[];
}

// PATCH /api/oee/alerts/:id/acknowledge
interface AcknowledgeAlertRequest {
  notes?: string;
}

// PATCH /api/oee/alerts/:id/resolve
interface ResolveAlertRequest {
  resolution_notes: string;
}
```

### Service Layer

```typescript
// lib/services/alert-service.ts

export class AlertService {
  static async listAlerts(params: AlertListParams): Promise<PaginatedResult<PerformanceAlert>>;
  static async getActiveAlerts(): Promise<{ alerts: PerformanceAlert[]; counts: any }>;
  static async getAlertById(id: string): Promise<PerformanceAlert | null>;

  static async acknowledgeAlert(id: string, userId: string, notes?: string): Promise<PerformanceAlert>;
  static async resolveAlert(id: string, userId: string, notes: string): Promise<PerformanceAlert>;
  static async dismissAlert(id: string, userId: string): Promise<PerformanceAlert>;

  static async createAlertRule(input: CreateAlertRuleInput): Promise<AlertRule>;
  static async updateAlertRule(id: string, input: UpdateAlertRuleInput): Promise<AlertRule>;
  static async deleteAlertRule(id: string): Promise<void>;
  static async listAlertRules(): Promise<AlertRule[]>;

  static async sendEmailNotification(alertId: string): Promise<boolean>;
  static async sendInAppNotification(alertId: string): Promise<void>;
}
```

---

## Deliverables

### Database
- [ ] Migration: `performance_alerts` table
- [ ] Migration: `alert_rules` table
- [ ] Function: `evaluate_oee_alert_thresholds()`
- [ ] Function: `evaluate_downtime_alert_thresholds()`
- [ ] Triggers on oee_snapshots and oee_downtime_events
- [ ] RLS policies for both tables
- [ ] Performance indexes

### API Routes
- [ ] `GET /api/oee/alerts` - List alerts
- [ ] `GET /api/oee/alerts/active` - Active alerts
- [ ] `GET /api/oee/alerts/:id` - Alert detail
- [ ] `PATCH /api/oee/alerts/:id/acknowledge` - Acknowledge
- [ ] `PATCH /api/oee/alerts/:id/resolve` - Resolve
- [ ] `POST /api/oee/alerts/config` - Create rule
- [ ] `PUT /api/oee/alerts/config/:id` - Update rule
- [ ] `DELETE /api/oee/alerts/config/:id` - Delete rule

### Service Layer
- [ ] `AlertService.listAlerts()`
- [ ] `AlertService.getActiveAlerts()`
- [ ] `AlertService.acknowledgeAlert()`
- [ ] `AlertService.resolveAlert()`
- [ ] `AlertService.sendEmailNotification()`

### Frontend
- [ ] Alert dashboard widget
- [ ] Alert list page
- [ ] Alert detail view
- [ ] Alert rule configuration page
- [ ] Notification panel
- [ ] Email templates

### Tests
- [ ] Unit tests: AlertService methods
- [ ] Integration tests: Alert API endpoints
- [ ] Trigger tests: Alert creation on threshold breach
- [ ] Email notification tests
- [ ] RLS tests: Org isolation

---

## Definition of Done

- [ ] All alert types trigger correctly
- [ ] Email notifications sent within 1 minute
- [ ] In-app notifications display in real-time
- [ ] Alert acknowledgment workflow complete
- [ ] Alert rule CRUD operations work
- [ ] Performance: Alert list < 500ms
- [ ] All tests passing (>80% coverage)
- [ ] RLS policies enforce org isolation

---

## Risk Assessment

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Alert fatigue from too many alerts | HIGH | MEDIUM | Configurable thresholds, smart grouping |
| Email delivery failures | MEDIUM | LOW | Retry logic, error logging, fallback to in-app |
| Performance with high alert volume | MEDIUM | LOW | Indexes, pagination, archival strategy |
| False positives | MEDIUM | MEDIUM | Evaluation period, consecutive violations |

---

**Document Status**: Ready for Implementation
**Created**: 2025-01-15
**Lines**: ~950
**Complexity**: M (Medium)
**Phase**: 1B (Alerts & Reports)
