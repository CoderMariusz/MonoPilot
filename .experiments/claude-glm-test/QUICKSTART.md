# Quick Start Guide

Szybki start testowania Claude + GLM multi-agent systemu.

## ğŸš€ Setup (5 minut)

### 1. Zainstaluj Python dependencies

```bash
pip install requests tiktoken
```

### 2. ZdobÄ…dÅº klucz API ZhipuAI

```bash
# OtwÃ³rz w przeglÄ…darce:
https://open.bigmodel.cn/usercenter/apikeys

# Lub szybka rejestracja:
# 1. WejdÅº na https://open.bigmodel.cn/
# 2. Sign up (moÅ¼e byÄ‡ przez WeChat/email)
# 3. Dashboard â†’ API Keys â†’ Create
# 4. Kopiuj klucz
```

### 3. Konfiguracja

```bash
cd .experiments/claude-glm-test

# Edytuj config.json - wklej swÃ³j API key:
nano config.json  # lub notepad config.json na Windows
```

```json
{
  "zhipu_api_key": "wklej_tutaj_swÃ³j_klucz"
}
```

## âœ… Test instalacji

SprawdÅº czy GLM API dziaÅ‚a:

```bash
python scripts/glm_call.py \
  --prompt "Hello, write a simple Python function that adds two numbers" \
  --model glm-4-flash
```

JeÅ›li zobaczysz kod funkcji - dziaÅ‚a! âœ“

## ğŸ§ª Pierwszy test porÃ³wnawczy

### Krok 1: Wybierz story do testu

Wybierz jedno story z Epic 05 Warehouse (Å›redniej zÅ‚oÅ¼onoÅ›ci):

```bash
# PrzykÅ‚ad: Story 05.1 - Warehouse Settings CRUD
# lub: Story 05.2 - License Plate Search
```

### Krok 2: Przygotuj pliki

```bash
cd test_scenarios/scenario_a_claude_only

# Skopiuj:
# 1. Story description â†’ input_story.md
# 2. Testy â†’ context_files/tests.test.ts
# 3. UX spec â†’ context_files/wireframe.md
# 4. Patterns â†’ context_files/patterns.md
```

**WAÅ»NE**: Skopiuj DOKÅADNIE TE SAME pliki do `scenario_b_claude_glm/`!

```bash
cd ../scenario_b_claude_glm

# Kopiuj te same pliki co w scenario A
cp ../scenario_a_claude_only/input_story.md .
cp -r ../scenario_a_claude_only/context_files/* context_files/
```

### Krok 3: TEST A - Claude Only

W Claude (Antigravity):

```
Zaimplementuj story z pliku:
.experiments/claude-glm-test/test_scenarios/scenario_a_claude_only/input_story.md

UÅ¼yj kontekstu z: context_files/
Zapisz wynik w: output_code.ts
```

Po zakoÅ„czeniu, policz tokeny:

```bash
cd .experiments/claude-glm-test

# Input
python scripts/count_tokens.py \
  test_scenarios/scenario_a_claude_only/input_story.md \
  test_scenarios/scenario_a_claude_only/context_files/*

# Output
python scripts/count_tokens.py \
  test_scenarios/scenario_a_claude_only/output_code.ts
```

Zapisz w `metrics.json`:
```json
{
  "scenario": "claude_only",
  "total_tokens": 8500,        // suma input + output
  "claude_tokens": 8500,
  "input_tokens": 5200,
  "output_tokens": 3300,
  "cost_usd": 0.0651,         // (5200 * 3 + 3300 * 15) / 1000000
  "iterations": 2
}
```

### Krok 4: TEST B - Claude + GLM

**Faza 1: Claude projektuje prompt**

W Claude:

```
Zaprojektuj prompt dla GLM-4-Plus do implementacji story:
.experiments/claude-glm-test/test_scenarios/scenario_b_claude_glm/input_story.md

UwzglÄ™dnij caÅ‚y kontekst z: context_files/
Zapisz w: claude_prompt_for_glm.md
```

Policz tokeny Claude (planning):
```bash
python scripts/count_tokens.py \
  test_scenarios/scenario_b_claude_glm/claude_prompt_for_glm.md
```

**Faza 2: GLM generuje kod**

Opcja A - przez skrypt:
```bash
python scripts/glm_call.py \
  --prompt "$(cat test_scenarios/scenario_b_claude_glm/claude_prompt_for_glm.md)" \
  --model glm-4-plus \
  --output test_scenarios/scenario_b_claude_glm/glm_output_code.ts \
  --json > glm_response.json
```

Opcja B - rÄ™cznie:
1. Wklej prompt do https://chatglm.cn/
2. Skopiuj kod do `glm_output_code.ts`

**Faza 3: Claude review**

W Claude:

```
ZrÃ³b code review kodu z GLM:
.experiments/claude-glm-test/test_scenarios/scenario_b_claude_glm/glm_output_code.ts

WzglÄ™dem story: input_story.md
Zapisz w: claude_review.md
```

Policz tokeny:
```bash
# Claude review phase
python scripts/count_tokens.py \
  test_scenarios/scenario_b_claude_glm/glm_output_code.ts \
  test_scenarios/scenario_b_claude_glm/claude_review.md
```

Zapisz w `metrics.json`:
```json
{
  "scenario": "claude_glm",
  "total_tokens": 12500,
  "claude_tokens": 2800,       // planning (800) + review (2000)
  "glm_tokens": 9700,
  "cost_usd": 0.0423,          // Claude + GLM
  "iterations": 2,
  "glm_iterations": 1
}
```

### Krok 5: PorÃ³wnaj

```bash
python scripts/compare_results.py
```

## ğŸ“Š Interpretacja wynikÃ³w

### Scenariusz SUCCESS (Claude + GLM wygrywa):

```
ğŸ’° SAVINGS (Scenario B vs A)
   Claude Tokens:   -5,700 (-67.1%)  âœ“ Åšwietnie!
   Cost:            -$0.0228 (-35%)  âœ“ OszczÄ™dnoÅ›Ä‡!

ğŸ† WINNER: Claude + GLM
```

â¡ï¸ **Warto kontynuowaÄ‡**: Zbuduj automatyzacjÄ™ orkiestratora.

### Scenariusz FAIL (Claude Only lepszy):

```
ğŸ’° SAVINGS (Scenario B vs A)
   Claude Tokens:   -2,100 (-24.7%)  âš ï¸ MaÅ‚a oszczÄ™dnoÅ›Ä‡
   Cost:            +$0.0050 (+7.7%)  âŒ DroÅ¼ej!

ğŸ† WINNER: Claude Only
```

â¡ï¸ **PrzemyÅ›l podziaÅ‚**: MoÅ¼e GLM tylko do prostych taskÃ³w (generowanie testÃ³w)?

## ğŸ¯ NastÄ™pne kroki

JeÅ›li test pozytywny:

1. **WiÄ™cej story**: Testuj na 3-5 rÃ³Å¼nych story (rÃ³Å¼ne complexity)
2. **RÃ³Å¼ne modele GLM**: PorÃ³wnaj glm-4-plus vs glm-4-long
3. **Automatyzacja**: Napisz orkiestrator Å‚Ä…czÄ…cy Claude + GLM
4. **Integracja**: Dodaj do MonoPilot 7-phase workflow

## ğŸ› Troubleshooting

### BÅ‚Ä…d: "ZHIPU_API_KEY not found"
```bash
# Ustaw w config.json lub export:
export ZHIPU_API_KEY="twÃ³j_klucz"
```

### BÅ‚Ä…d: "tiktoken not installed"
```bash
pip install tiktoken
# Lub skrypt uÅ¼yje prostego licznika sÅ‚Ã³w * 1.3
```

### GLM zwraca bÅ‚Ä…d 401
- SprawdÅº klucz API w config.json
- SprawdÅº czy masz tokeny na koncie (https://open.bigmodel.cn/usercenter/apikeys)

### Wyniki nie majÄ… sensu
- Upewnij siÄ™ Å¼e oba scenariusze uÅ¼ywajÄ… DOKÅADNIE tych samych plikÃ³w kontekstowych
- Policz wszystkie iteracje (nie tylko pierwszÄ…)

## ğŸ“š PeÅ‚na dokumentacja

Zobacz `README.md` dla szczegÃ³Å‚Ã³w.
