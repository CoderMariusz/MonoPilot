# üöÄ Quick Start Guide - Multi-Agent Implementation

**Goal**: Implement Claude + GLM + DeepSeek hybrid workflow for MonoPilot
**Expected Result**: 60-75% cost savings with identical quality
**Time to First Results**: 3 days

---

## üìä Your Test Results (Reminder)

```
Story 03.2: Supplier-Product Assignments

Scenario A (Claude Only):
  Cost: $0.437
  Quality: 10/10 ACs, 96% tests, 9.5/10 code

Scenario B (Claude + GLM Hybrid):
  Cost: $0.206  (-53%! üéâ)
  Quality: 10/10 ACs, 96% tests, 9.5/10 code (IDENTICAL)

‚úÖ Proven: Hybrid = Same quality, half the cost
```

---

## üéØ Phase 1: Quick Wins (Week 1)

### Day 1: Setup

#### 1. Create Orchestrator Project

```bash
# From monopilot root
cd apps/
mkdir orchestrator
cd orchestrator

# Initialize
pnpm init
pnpm add @langchain/langgraph @langchain/core @langchain/anthropic
pnpm add @anthropic-ai/sdk zod dotenv
pnpm add -D typescript @types/node tsx vitest

# Create structure
mkdir -p src/{clients,nodes,routing,checkpoints,metrics}
mkdir -p tests
```

#### 2. Setup Environment Variables

```bash
# apps/orchestrator/.env
ANTHROPIC_API_KEY=your-claude-key
DEEPSEEK_API_KEY=your-deepseek-key  # Get from https://platform.deepseek.com
ZHIPU_API_KEY=your-glm-key          # From ../../.experiments/claude-glm-test/config.json
```

#### 3. Copy Base Files

```bash
# Copy client implementations
cp ../../.experiments/claude-glm-test/scripts/glm_call.py src/clients/glm-client.ts  # Convert to TS
cp ../../.experiments/claude-glm-test/guides/DEEPSEEK_API_GUIDE.md docs/  # Reference

# Copy templates
cp ../../.claude/templates/MONOPILOT-BACKEND-PATTERNS.md .claude/templates/

# Copy LangGraph example
cp ../../.experiments/claude-glm-test/guides/LANGGRAPH_GUIDE.md docs/
```

---

### Day 2: Implement Core Clients

#### 1. Claude Client

```typescript
// src/clients/claude-client.ts
import Anthropic from '@anthropic-ai/sdk';
import 'dotenv/config';

export function createClaudeClient() {
  return new Anthropic({
    apiKey: process.env.ANTHROPIC_API_KEY,
  });
}
```

#### 2. GLM Client

```typescript
// src/clients/glm-client.ts
import 'dotenv/config';

interface GLMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export class GLMClient {
  private apiKey: string;
  private baseURL = 'https://open.bigmodel.cn/api/paas/v4';

  constructor(apiKey?: string) {
    this.apiKey = apiKey || process.env.ZHIPU_API_KEY || '';
  }

  async chat(options: {
    model: string;
    messages: GLMMessage[];
    temperature?: number;
  }) {
    const response = await fetch(`${this.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify({
        model: options.model,
        messages: options.messages,
        temperature: options.temperature ?? 0.7,
      }),
    });

    if (!response.ok) {
      throw new Error(`GLM API error: ${response.status}`);
    }

    return response.json();
  }
}

export function createGLMClient() {
  return new GLMClient();
}
```

#### 3. DeepSeek Client

```typescript
// src/clients/deepseek-client.ts
import 'dotenv/config';

export class DeepSeekClient {
  private apiKey: string;
  private baseURL = 'https://api.deepseek.com/v1';

  constructor(apiKey?: string) {
    this.apiKey = apiKey || process.env.DEEPSEEK_API_KEY || '';
  }

  async chat(messages: any[], options: any = {}) {
    const response = await fetch(`${this.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify({
        model: options.model || 'deepseek-coder',
        messages,
        temperature: options.temperature ?? 0.7,
        max_tokens: options.max_tokens ?? 4096,
      }),
    });

    if (!response.ok) {
      throw new Error(`DeepSeek API error: ${response.status}`);
    }

    const data = await response.json();

    return {
      content: data.choices[0].message.content,
      usage: data.usage,
    };
  }

  calculateCost(tokens: number): number {
    return (tokens * 0.14) / 1_000_000;
  }
}

export function createDeepSeekClient() {
  return new DeepSeekClient();
}
```

---

### Day 3: Test API Connections

```typescript
// tests/api-connections.test.ts
import { describe, it, expect } from 'vitest';
import { createClaudeClient } from '../src/clients/claude-client';
import { createGLMClient } from '../src/clients/glm-client';
import { createDeepSeekClient } from '../src/clients/deepseek-client';

describe('API Connections', () => {
  it('should connect to Claude', async () => {
    const claude = createClaudeClient();
    const response = await claude.messages.create({
      model: 'claude-opus-4',
      max_tokens: 100,
      messages: [{ role: 'user', content: 'Say "test successful"' }],
    });

    expect(response.content[0].type).toBe('text');
    console.log('‚úÖ Claude connected');
  });

  it('should connect to GLM', async () => {
    const glm = createGLMClient();
    const response = await glm.chat({
      model: 'glm-4-plus',
      messages: [{ role: 'user', content: 'Say "test successful"' }],
    });

    expect(response.choices[0].message.content).toBeTruthy();
    console.log('‚úÖ GLM connected');
  });

  it('should connect to DeepSeek', async () => {
    const deepseek = createDeepSeekClient();
    const response = await deepseek.chat([
      { role: 'user', content: 'Say "test successful"' },
    ]);

    expect(response.content).toBeTruthy();
    console.log('‚úÖ DeepSeek connected');
  });
});
```

```bash
# Run tests
pnpm exec vitest run tests/api-connections.test.ts
```

**Expected Output**:
```
‚úÖ Claude connected
‚úÖ GLM connected
‚úÖ DeepSeek connected

Test Suites: 1 passed
Tests: 3 passed
```

---

## üéØ Week 1 Checkpoint

After Day 3, you should have:
- [ ] Orchestrator project setup
- [ ] 3 model clients working
- [ ] API connections verified
- [ ] Templates ready

**Next**: Implement semantic routing

---

## üìä Day 4-5: Semantic Routing

### 1. Complexity Analyzer

```typescript
// src/routing/complexity-analyzer.ts
export function analyzeComplexity(state: { story_description: string }): number {
  const { story_description } = state;

  let score = 0;

  // Check for complex keywords
  const complexKeywords = [
    'algorithm', 'optimization', 'calculation', 'formula',
    'business rule', 'workflow', 'state machine', 'integration'
  ];

  const simpleKeywords = [
    'CRUD', 'list', 'display', 'view', 'table', 'form',
    'create', 'read', 'update', 'delete'
  ];

  complexKeywords.forEach(keyword => {
    if (story_description.toLowerCase().includes(keyword)) {
      score += 0.2;
    }
  });

  simpleKeywords.forEach(keyword => {
    if (story_description.toLowerCase().includes(keyword)) {
      score -= 0.1;
    }
  });

  // Normalize to 0-1
  return Math.max(0, Math.min(1, score + 0.5));
}

export function selectModel(complexity: number): {
  model: 'claude' | 'glm-4-plus' | 'glm-4-flash' | 'deepseek';
  reason: string;
} {
  if (complexity > 0.7) {
    return { model: 'claude', reason: 'High complexity - needs strategic thinking' };
  } else if (complexity > 0.3) {
    return { model: 'glm-4-plus', reason: 'Medium complexity - GLM-4-Plus can handle' };
  } else {
    return { model: 'glm-4-flash', reason: 'Simple task - use cheap model' };
  }
}
```

### 2. Test Routing

```typescript
// tests/routing.test.ts
import { analyzeComplexity, selectModel } from '../src/routing/complexity-analyzer';

describe('Semantic Routing', () => {
  it('should route complex tasks to Claude', () => {
    const state = {
      story_description: 'Implement FIFO allocation algorithm with business rules'
    };

    const complexity = analyzeComplexity(state);
    const { model } = selectModel(complexity);

    expect(model).toBe('claude');
  });

  it('should route simple CRUD to GLM-Flash', () => {
    const state = {
      story_description: 'Create a table to view and edit supplier list'
    };

    const complexity = analyzeComplexity(state);
    const { model } = selectModel(complexity);

    expect(model).toBe('glm-4-flash');
  });
});
```

**Expected Savings**: +10-15% by using GLM-Flash for simple tasks

---

## üéØ Day 6-7: First Full Workflow

### Minimal LangGraph Workflow

```typescript
// src/simple-workflow.ts
import { StateGraph, START, END, Annotation } from '@langchain/langgraph';
import { createClaudeClient } from './clients/claude-client';
import { createGLMClient } from './clients/glm-client';
import { createDeepSeekClient } from './clients/deepseek-client';

// Define state
const StateAnnotation = Annotation.Root({
  story_id: Annotation<string>,
  story_title: Annotation<string>,
  story_description: Annotation<string>,
  tests: Annotation<string | null>,
  code: Annotation<string | null>,
  total_cost: Annotation<number>,
});

type WorkflowState = typeof StateAnnotation.State;

// P2: DeepSeek writes tests
async function p2TestWriter(state: WorkflowState) {
  console.log('üß™ P2: Writing tests with DeepSeek...');

  const deepseek = createDeepSeekClient();

  const response = await deepseek.chat([
    {
      role: 'user',
      content: `Generate Vitest tests for: ${state.story_description}`
    },
  ]);

  const cost = deepseek.calculateCost(response.usage.total_tokens);

  return {
    tests: response.content,
    total_cost: state.total_cost + cost,
  };
}

// P3: GLM writes code
async function p3CodeGenerator(state: WorkflowState) {
  console.log('üíª P3: Generating code with GLM...');

  const glm = createGLMClient();

  const response = await glm.chat({
    model: 'glm-4-plus',
    messages: [
      {
        role: 'user',
        content: `Implement this feature:\n${state.story_description}\n\nTests to pass:\n${state.tests}`
      },
    ],
  });

  const cost = (response.usage.total_tokens * 0.70) / 1_000_000;

  return {
    code: response.choices[0].message.content,
    total_cost: state.total_cost + cost,
  };
}

// Build workflow
export function createSimpleWorkflow() {
  const workflow = new StateGraph(StateAnnotation);

  workflow.addNode('p2_tests', p2TestWriter);
  workflow.addNode('p3_code', p3CodeGenerator);

  workflow.addEdge(START, 'p2_tests');
  workflow.addEdge('p2_tests', 'p3_code');
  workflow.addEdge('p3_code', END);

  return workflow.compile();
}
```

### Run It

```typescript
// src/index.ts
import { createSimpleWorkflow } from './simple-workflow';

async function main() {
  const app = createSimpleWorkflow();

  const result = await app.invoke({
    story_id: '03.2',
    story_title: 'Supplier-Product Assignments',
    story_description: 'Allow assigning products to suppliers with pricing',
    tests: null,
    code: null,
    total_cost: 0,
  });

  console.log('\n‚úÖ Workflow completed!');
  console.log(`üí∞ Total cost: $${result.total_cost.toFixed(4)}`);
  console.log(`\nüìù Tests:\n${result.tests?.substring(0, 500)}...`);
  console.log(`\nüíª Code:\n${result.code?.substring(0, 500)}...`);
}

main().catch(console.error);
```

```bash
# Run
pnpm exec tsx src/index.ts
```

**Expected Output**:
```
üß™ P2: Writing tests with DeepSeek...
üíª P3: Generating code with GLM...

‚úÖ Workflow completed!
üí∞ Total cost: $0.0026  # vs Claude-only: $0.06 (96% cheaper!)

üìù Tests:
import { describe, it, expect } from 'vitest'...

üíª Code:
export class SupplierProductService {...
```

---

## üéâ Week 1 Success Criteria

After Week 1, you should have:

### ‚úÖ Technical Setup
- [ ] Orchestrator project with 3 model clients
- [ ] Semantic routing working
- [ ] Simple 2-phase workflow (P2 + P3) running
- [ ] Cost tracking implemented

### ‚úÖ Results
- [ ] Successfully generated tests with DeepSeek
- [ ] Successfully generated code with GLM
- [ ] Total cost <$0.01 for test story
- [ ] 60-75% savings vs Claude-only

### ‚úÖ Validation
- [ ] All API connections tested
- [ ] Routing logic tested
- [ ] Cost calculations verified
- [ ] Output quality manually reviewed

---

## üìÖ Week 2-3: Full 7-Phase Workflow

### Add Missing Phases

1. **P1: UX Designer** (Claude)
2. **P5: Code Reviewer** (Claude) ‚Üê CRITICAL
3. **P5‚ÜíP3 Iteration Loop**
4. **P6: QA Tester** (Claude)
5. **P7: Doc Writer** (DeepSeek)

**Reference**: See `.experiments/claude-glm-test/guides/LANGGRAPH_GUIDE.md` for complete implementation

---

## üìä Monitoring Dashboard

### Track Metrics

```typescript
// src/metrics/tracker.ts
export class MetricsTracker {
  static metrics = {
    stories_processed: 0,
    total_cost: 0,
    by_model: {} as Record<string, { tokens: number; cost: number }>,
    by_phase: {} as Record<string, { tokens: number; cost: number }>,
  };

  static track(model: string, phase: string, tokens: number, cost: number) {
    this.metrics.stories_processed++;
    this.metrics.total_cost += cost;

    // By model
    if (!this.metrics.by_model[model]) {
      this.metrics.by_model[model] = { tokens: 0, cost: 0 };
    }
    this.metrics.by_model[model].tokens += tokens;
    this.metrics.by_model[model].cost += cost;

    // By phase
    if (!this.metrics.by_phase[phase]) {
      this.metrics.by_phase[phase] = { tokens: 0, cost: 0 };
    }
    this.metrics.by_phase[phase].tokens += tokens;
    this.metrics.by_phase[phase].cost += cost;
  }

  static getReport() {
    return {
      ...this.metrics,
      avg_cost_per_story: this.metrics.total_cost / this.metrics.stories_processed,
    };
  }
}
```

---

## üéØ Next Steps After Week 1

### If Results are Good (>60% savings, same quality):
1. ‚úÖ Continue to Week 2-3 (Full 7-phase workflow)
2. ‚úÖ Test on 5 more stories
3. ‚úÖ Document learnings
4. ‚úÖ Present to team

### If Results Need Improvement:
1. ‚ö†Ô∏è Review prompts (add more context)
2. ‚ö†Ô∏è Adjust complexity thresholds
3. ‚ö†Ô∏è Try different models for specific phases
4. ‚ö†Ô∏è Re-test on same story

---

## üìö Resources

### Documentation
- **Master Plan**: `.experiments/claude-glm-test/IMPLEMENTATION_MASTER_PLAN.md`
- **LangGraph Guide**: `.experiments/claude-glm-test/guides/LANGGRAPH_GUIDE.md`
- **DeepSeek Guide**: `.experiments/claude-glm-test/guides/DEEPSEEK_API_GUIDE.md`
- **Backend Patterns**: `.claude/templates/MONOPILOT-BACKEND-PATTERNS.md`

### Test Results
- **Final Report**: `.experiments/claude-glm-test/FINAL_COMPARISON_REPORT.md`
- **Quality Analysis**: `.experiments/claude-glm-test/QUALITY_ANALYSIS_REPORT.md`

### API Keys
- **DeepSeek**: https://platform.deepseek.com/api_keys
- **GLM (ZhipuAI)**: https://open.bigmodel.cn/ (already have in config.json)
- **Claude**: Already configured

---

## ‚úÖ Quick Start Checklist

**Before you start**:
- [ ] Read test results (you already did!)
- [ ] Read master plan
- [ ] Get DeepSeek API key

**Day 1**:
- [ ] Create orchestrator project
- [ ] Setup environment variables
- [ ] Install dependencies

**Day 2**:
- [ ] Implement 3 model clients
- [ ] Test API connections

**Day 3**:
- [ ] Verify all clients work
- [ ] Fix any connection issues

**Day 4-5**:
- [ ] Implement semantic routing
- [ ] Test routing logic

**Day 6-7**:
- [ ] Build simple 2-phase workflow
- [ ] Run on test story
- [ ] Measure savings

**End of Week 1**:
- [ ] Validate 60-75% savings
- [ ] Validate same quality
- [ ] Decide: continue or adjust

---

## üí¨ Support

**Questions?** Check:
1. Test results (`.experiments/claude-glm-test/FINAL_COMPARISON_REPORT.md`)
2. Implementation plan (`.experiments/claude-glm-test/IMPLEMENTATION_MASTER_PLAN.md`)
3. Specific guides (`./guides/*.md`)

**Stuck?** Common issues:
- **API key error**: Check `.env` file
- **Connection timeout**: Check internet, try again
- **Cost too high**: Review model selection, check routing logic
- **Quality issues**: Add more context to prompts, lower temperature

---

**üöÄ Ready to start? Begin with Day 1!**

**Expected Timeline**: Week 1 foundation ‚Üí Week 2-3 full workflow ‚Üí Week 4+ production use

**Expected ROI**: $46 savings on next 100 stories (75% cost reduction)
